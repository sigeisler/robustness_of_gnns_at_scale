{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seml\n",
    "import pandas as pd\n",
    "from run_seml import run\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=726.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aff8055fdbd14ce5a9a5d64f5bd4a539"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=726.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f91e1c503ca24ef58b0642a649bd2a51"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seml_results = seml.get_results('rgnn_rpprgo_cora_citeseer', to_data_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['_id', 'config.overwrite', 'config.db_collection', 'config.dataset',\n",
       "       'config.model_params.label', 'config.model_params.model',\n",
       "       'config.model_params.dropout', 'config.model_params.n_filters',\n",
       "       'config.model_params.gdc_params', 'config.model_params.svd_params',\n",
       "       'config.model_params.jaccard_params',\n",
       "       'config.model_params.do_cache_adj_prep', 'config.model_params.alpha',\n",
       "       'config.model_params.eps', 'config.model_params.hidden_size',\n",
       "       'config.model_params.mean', 'config.model_params.mean_kwargs.k',\n",
       "       'config.model_params.mean_kwargs.temperature',\n",
       "       'config.model_params.mean_kwargs.with_weight_correction',\n",
       "       'config.model_params.nlayers', 'config.model_params.ppr_normalization',\n",
       "       'config.model_params.topk', 'config.train_params.lr',\n",
       "       'config.train_params.weight_decay', 'config.train_params.patience',\n",
       "       'config.train_params.max_epochs', 'config.train_params.batch_mult_val',\n",
       "       'config.train_params.batch_size', 'config.binary_attr', 'config.seed',\n",
       "       'config.artifact_dir', 'config.model_storage_type', 'config.device',\n",
       "       'config.display_steps', 'config.data_device', 'config.data_dir',\n",
       "       'result.accuracy', 'result.trace_val', 'result.trace_train',\n",
       "       'result.model_path'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "relevant_columns = ['_id', 'config.dataset', 'config.model_params.model',\n",
    "       'config.model_params.dropout', \n",
    "       'config.model_params.do_cache_adj_prep', \n",
    "       'config.model_params.alpha',\n",
    "       'config.model_params.eps',\n",
    "        'config.model_params.hidden_size',\n",
    "       #'config.model_params.mean',\n",
    "       #'config.model_params.mean_kwargs.k',\n",
    "       'config.model_params.mean_kwargs.temperature',\n",
    "       #'config.model_params.mean_kwargs.with_weight_correction',\n",
    "       'config.model_params.nlayers',\n",
    "       # 'config.model_params.ppr_normalization',\n",
    "       #'config.model_params.topk', \n",
    "       #'config.train_params.lr',\n",
    "       #'config.train_params.weight_decay', 'config.train_params.patience',\n",
    "       #'config.train_params.max_epochs', 'config.train_params.batch_mult_val',\n",
    "       #'config.train_params.batch_size', 'config.binary_attr', 'config.seed',\n",
    "       #'config.artifact_dir', 'config.model_storage_type', 'config.device',\n",
    "       #'config.display_steps', 'config.data_device', 'config.data_dir',\n",
    "       'result.accuracy',\n",
    "       # 'result.trace_val', 'result.trace_train',\n",
    "       #'result.model_path'\n",
    "       ]\n",
    "seml_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_results = seml_results[seml_results[\"config.dataset\"] == \"cora_ml\"]\n",
    "citeseer_results = seml_results[seml_results[\"config.dataset\"] == \"citeseer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    _id config.dataset config.model_params.model  config.model_params.dropout  \\\n",
       "45   46        cora_ml               RobustPPRGo                         0.25   \n",
       "\n",
       "    config.model_params.do_cache_adj_prep  config.model_params.alpha  \\\n",
       "45                                   True                       0.25   \n",
       "\n",
       "    config.model_params.eps  config.model_params.hidden_size  \\\n",
       "45                     0.01                               64   \n",
       "\n",
       "    config.model_params.mean_kwargs.temperature  config.model_params.nlayers  \\\n",
       "45                                         50.0                            2   \n",
       "\n",
       "    result.accuracy  \n",
       "45         0.750988  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>config.dataset</th>\n      <th>config.model_params.model</th>\n      <th>config.model_params.dropout</th>\n      <th>config.model_params.do_cache_adj_prep</th>\n      <th>config.model_params.alpha</th>\n      <th>config.model_params.eps</th>\n      <th>config.model_params.hidden_size</th>\n      <th>config.model_params.mean_kwargs.temperature</th>\n      <th>config.model_params.nlayers</th>\n      <th>result.accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>45</th>\n      <td>46</td>\n      <td>cora_ml</td>\n      <td>RobustPPRGo</td>\n      <td>0.25</td>\n      <td>True</td>\n      <td>0.25</td>\n      <td>0.01</td>\n      <td>64</td>\n      <td>50.0</td>\n      <td>2</td>\n      <td>0.750988</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "metric = \"result.accuracy\"\n",
    "best_cora_results = cora_results[cora_results[metric] == cora_results[metric].max()]#.drop_duplicates([metric])\n",
    "best_cora_results[relevant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      _id config.dataset config.model_params.model  \\\n",
       "324   799       citeseer               RobustPPRGo   \n",
       "624  1099       citeseer               RobustPPRGo   \n",
       "\n",
       "     config.model_params.dropout  config.model_params.do_cache_adj_prep  \\\n",
       "324                          0.1                                   True   \n",
       "624                          0.1                                   True   \n",
       "\n",
       "     config.model_params.alpha  config.model_params.eps  \\\n",
       "324                       0.25                     0.01   \n",
       "624                       0.25                     0.01   \n",
       "\n",
       "     config.model_params.hidden_size  \\\n",
       "324                               32   \n",
       "624                               32   \n",
       "\n",
       "     config.model_params.mean_kwargs.temperature  config.model_params.nlayers  \\\n",
       "324                                         20.0                            2   \n",
       "624                                         20.0                            2   \n",
       "\n",
       "     result.accuracy  \n",
       "324         0.733155  \n",
       "624         0.733155  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>config.dataset</th>\n      <th>config.model_params.model</th>\n      <th>config.model_params.dropout</th>\n      <th>config.model_params.do_cache_adj_prep</th>\n      <th>config.model_params.alpha</th>\n      <th>config.model_params.eps</th>\n      <th>config.model_params.hidden_size</th>\n      <th>config.model_params.mean_kwargs.temperature</th>\n      <th>config.model_params.nlayers</th>\n      <th>result.accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>324</th>\n      <td>799</td>\n      <td>citeseer</td>\n      <td>RobustPPRGo</td>\n      <td>0.1</td>\n      <td>True</td>\n      <td>0.25</td>\n      <td>0.01</td>\n      <td>32</td>\n      <td>20.0</td>\n      <td>2</td>\n      <td>0.733155</td>\n    </tr>\n    <tr>\n      <th>624</th>\n      <td>1099</td>\n      <td>citeseer</td>\n      <td>RobustPPRGo</td>\n      <td>0.1</td>\n      <td>True</td>\n      <td>0.25</td>\n      <td>0.01</td>\n      <td>32</td>\n      <td>20.0</td>\n      <td>2</td>\n      <td>0.733155</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "best_citeseer_results = citeseer_results[citeseer_results[metric] == citeseer_results[metric].max()]#.drop_duplicates([metric])\n",
    "best_citeseer_results[relevant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "config.binary_attr\n",
       "True    0.630146\n",
       "Name: result.accuracy, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "\n",
    "cora_results.groupby([\"config.binary_attr\"]).mean()['result.accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     _id  config.overwrite config.db_collection config.aggr  config.alpha  \\\n",
       "256  257               257     pprgo_robust_hpt         sum          0.25   \n",
       "97    98                98     pprgo_robust_hpt        mean          0.25   \n",
       "162  163               163     pprgo_robust_hpt         sum          0.25   \n",
       "\n",
       "    config.attr_normalization  config.batch_mult_val  config.batch_size  \\\n",
       "256                      None                      4                512   \n",
       "97                       None                      4                512   \n",
       "162                      None                      4                512   \n",
       "\n",
       "       config.data_dir config.data_fname  config.dropout  config.early_stop  \\\n",
       "256  /nfs/shared/data/       cora_ml.npz             0.1              False   \n",
       "97   /nfs/shared/data/       cora_ml.npz             0.1              False   \n",
       "162  /nfs/shared/data/       cora_ml.npz             0.1              False   \n",
       "\n",
       "     config.eps  config.eval_step  config.hidden_size  config.inf_fraction  \\\n",
       "256      0.0001                 1                  64                  1.0   \n",
       "97       0.0100                 1                  64                  1.0   \n",
       "162      0.0001                 1                  32                  1.0   \n",
       "\n",
       "     config.lr  config.max_epochs config.model_class  config.nlayers  \\\n",
       "256      0.005                200              PPRGo               3   \n",
       "97       0.005                200              PPRGo               3   \n",
       "162      0.005                200        RobustPPRGo               2   \n",
       "\n",
       "     config.nprop_inference  config.ntrain_div_classes  config.patience  \\\n",
       "256                       2                         20               50   \n",
       "97                        2                         20               50   \n",
       "162                       2                         20               50   \n",
       "\n",
       "    config.ppr_normalization  config.run_val  config.split_seed  config.topk  \\\n",
       "256                      sym           False                  0           64   \n",
       "97                       sym           False                  0           32   \n",
       "162                      sym           False                  0           64   \n",
       "\n",
       "     config.weight_decay  config.seed  result.accuracy_train  \\\n",
       "256               0.0001    193365799                  100.0   \n",
       "97                0.0001    816813867                  100.0   \n",
       "162               0.0001    713012254                  100.0   \n",
       "\n",
       "     result.accuracy_val  result.accuracy_test  result.f1_train  \\\n",
       "256            84.214286             83.228346              1.0   \n",
       "97             82.357143             80.551181              1.0   \n",
       "162            81.000000             80.000000              1.0   \n",
       "\n",
       "     result.f1_val  result.f1_test  result.time_loading  \\\n",
       "256       0.824840        0.817294             0.022120   \n",
       "97        0.797865        0.784930             0.030133   \n",
       "162       0.782417        0.774175             0.027173   \n",
       "\n",
       "     result.time_preprocessing  result.time_training  result.time_inference  \\\n",
       "256                   6.103832              4.965747               0.010279   \n",
       "97                    5.852289              5.207305               0.011709   \n",
       "162                   5.920595              7.054422               0.008557   \n",
       "\n",
       "     result.time_logits  result.time_propagation  result.gpu_memory  \\\n",
       "256            0.007525                 0.002694           32934400   \n",
       "97             0.008917                 0.002738           10279936   \n",
       "162            0.005861                 0.002642           33509888   \n",
       "\n",
       "     result.memory  result.nepochs  \n",
       "256     2130378752             200  \n",
       "97      2121785344             200  \n",
       "162     2360094720             200  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>config.overwrite</th>\n      <th>config.db_collection</th>\n      <th>config.aggr</th>\n      <th>config.alpha</th>\n      <th>config.attr_normalization</th>\n      <th>config.batch_mult_val</th>\n      <th>config.batch_size</th>\n      <th>config.data_dir</th>\n      <th>config.data_fname</th>\n      <th>config.dropout</th>\n      <th>config.early_stop</th>\n      <th>config.eps</th>\n      <th>config.eval_step</th>\n      <th>config.hidden_size</th>\n      <th>config.inf_fraction</th>\n      <th>config.lr</th>\n      <th>config.max_epochs</th>\n      <th>config.model_class</th>\n      <th>config.nlayers</th>\n      <th>config.nprop_inference</th>\n      <th>config.ntrain_div_classes</th>\n      <th>config.patience</th>\n      <th>config.ppr_normalization</th>\n      <th>config.run_val</th>\n      <th>config.split_seed</th>\n      <th>config.topk</th>\n      <th>config.weight_decay</th>\n      <th>config.seed</th>\n      <th>result.accuracy_train</th>\n      <th>result.accuracy_val</th>\n      <th>result.accuracy_test</th>\n      <th>result.f1_train</th>\n      <th>result.f1_val</th>\n      <th>result.f1_test</th>\n      <th>result.time_loading</th>\n      <th>result.time_preprocessing</th>\n      <th>result.time_training</th>\n      <th>result.time_inference</th>\n      <th>result.time_logits</th>\n      <th>result.time_propagation</th>\n      <th>result.gpu_memory</th>\n      <th>result.memory</th>\n      <th>result.nepochs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>256</th>\n      <td>257</td>\n      <td>257</td>\n      <td>pprgo_robust_hpt</td>\n      <td>sum</td>\n      <td>0.25</td>\n      <td>None</td>\n      <td>4</td>\n      <td>512</td>\n      <td>/nfs/shared/data/</td>\n      <td>cora_ml.npz</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.0001</td>\n      <td>1</td>\n      <td>64</td>\n      <td>1.0</td>\n      <td>0.005</td>\n      <td>200</td>\n      <td>PPRGo</td>\n      <td>3</td>\n      <td>2</td>\n      <td>20</td>\n      <td>50</td>\n      <td>sym</td>\n      <td>False</td>\n      <td>0</td>\n      <td>64</td>\n      <td>0.0001</td>\n      <td>193365799</td>\n      <td>100.0</td>\n      <td>84.214286</td>\n      <td>83.228346</td>\n      <td>1.0</td>\n      <td>0.824840</td>\n      <td>0.817294</td>\n      <td>0.022120</td>\n      <td>6.103832</td>\n      <td>4.965747</td>\n      <td>0.010279</td>\n      <td>0.007525</td>\n      <td>0.002694</td>\n      <td>32934400</td>\n      <td>2130378752</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>98</td>\n      <td>98</td>\n      <td>pprgo_robust_hpt</td>\n      <td>mean</td>\n      <td>0.25</td>\n      <td>None</td>\n      <td>4</td>\n      <td>512</td>\n      <td>/nfs/shared/data/</td>\n      <td>cora_ml.npz</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.0100</td>\n      <td>1</td>\n      <td>64</td>\n      <td>1.0</td>\n      <td>0.005</td>\n      <td>200</td>\n      <td>PPRGo</td>\n      <td>3</td>\n      <td>2</td>\n      <td>20</td>\n      <td>50</td>\n      <td>sym</td>\n      <td>False</td>\n      <td>0</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>816813867</td>\n      <td>100.0</td>\n      <td>82.357143</td>\n      <td>80.551181</td>\n      <td>1.0</td>\n      <td>0.797865</td>\n      <td>0.784930</td>\n      <td>0.030133</td>\n      <td>5.852289</td>\n      <td>5.207305</td>\n      <td>0.011709</td>\n      <td>0.008917</td>\n      <td>0.002738</td>\n      <td>10279936</td>\n      <td>2121785344</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>163</td>\n      <td>163</td>\n      <td>pprgo_robust_hpt</td>\n      <td>sum</td>\n      <td>0.25</td>\n      <td>None</td>\n      <td>4</td>\n      <td>512</td>\n      <td>/nfs/shared/data/</td>\n      <td>cora_ml.npz</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.0001</td>\n      <td>1</td>\n      <td>32</td>\n      <td>1.0</td>\n      <td>0.005</td>\n      <td>200</td>\n      <td>RobustPPRGo</td>\n      <td>2</td>\n      <td>2</td>\n      <td>20</td>\n      <td>50</td>\n      <td>sym</td>\n      <td>False</td>\n      <td>0</td>\n      <td>64</td>\n      <td>0.0001</td>\n      <td>713012254</td>\n      <td>100.0</td>\n      <td>81.000000</td>\n      <td>80.000000</td>\n      <td>1.0</td>\n      <td>0.782417</td>\n      <td>0.774175</td>\n      <td>0.027173</td>\n      <td>5.920595</td>\n      <td>7.054422</td>\n      <td>0.008557</td>\n      <td>0.005861</td>\n      <td>0.002642</td>\n      <td>33509888</td>\n      <td>2360094720</td>\n      <td>200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "best_results = pd.concat([best_pprgo_results_sum, best_pprgo_results_mean, best_robust_pprgo_results])\n",
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     _id  config.overwrite config.aggr config.attr_normalization  config.eps  \\\n",
       "256  257               257         sum                      None      0.0001   \n",
       "97    98                98        mean                      None      0.0100   \n",
       "162  163               163         sum                      None      0.0001   \n",
       "\n",
       "     config.hidden_size config.model_class  config.nlayers  config.topk  \\\n",
       "256                  64              PPRGo               3           64   \n",
       "97                   64              PPRGo               3           32   \n",
       "162                  32        RobustPPRGo               2           64   \n",
       "\n",
       "     config.seed  result.accuracy_val  result.accuracy_test  result.f1_val  \\\n",
       "256    193365799            84.214286             83.228346       0.824840   \n",
       "97     816813867            82.357143             80.551181       0.797865   \n",
       "162    713012254            81.000000             80.000000       0.782417   \n",
       "\n",
       "     result.f1_test  result.time_loading  result.time_preprocessing  \\\n",
       "256        0.817294             0.022120                   6.103832   \n",
       "97         0.784930             0.030133                   5.852289   \n",
       "162        0.774175             0.027173                   5.920595   \n",
       "\n",
       "     result.time_training  result.time_inference  result.time_logits  \\\n",
       "256              4.965747               0.010279            0.007525   \n",
       "97               5.207305               0.011709            0.008917   \n",
       "162              7.054422               0.008557            0.005861   \n",
       "\n",
       "     result.time_propagation  result.gpu_memory  result.memory  \n",
       "256                 0.002694           32934400     2130378752  \n",
       "97                  0.002738           10279936     2121785344  \n",
       "162                 0.002642           33509888     2360094720  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>config.overwrite</th>\n      <th>config.aggr</th>\n      <th>config.attr_normalization</th>\n      <th>config.eps</th>\n      <th>config.hidden_size</th>\n      <th>config.model_class</th>\n      <th>config.nlayers</th>\n      <th>config.topk</th>\n      <th>config.seed</th>\n      <th>result.accuracy_val</th>\n      <th>result.accuracy_test</th>\n      <th>result.f1_val</th>\n      <th>result.f1_test</th>\n      <th>result.time_loading</th>\n      <th>result.time_preprocessing</th>\n      <th>result.time_training</th>\n      <th>result.time_inference</th>\n      <th>result.time_logits</th>\n      <th>result.time_propagation</th>\n      <th>result.gpu_memory</th>\n      <th>result.memory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>256</th>\n      <td>257</td>\n      <td>257</td>\n      <td>sum</td>\n      <td>None</td>\n      <td>0.0001</td>\n      <td>64</td>\n      <td>PPRGo</td>\n      <td>3</td>\n      <td>64</td>\n      <td>193365799</td>\n      <td>84.214286</td>\n      <td>83.228346</td>\n      <td>0.824840</td>\n      <td>0.817294</td>\n      <td>0.022120</td>\n      <td>6.103832</td>\n      <td>4.965747</td>\n      <td>0.010279</td>\n      <td>0.007525</td>\n      <td>0.002694</td>\n      <td>32934400</td>\n      <td>2130378752</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>98</td>\n      <td>98</td>\n      <td>mean</td>\n      <td>None</td>\n      <td>0.0100</td>\n      <td>64</td>\n      <td>PPRGo</td>\n      <td>3</td>\n      <td>32</td>\n      <td>816813867</td>\n      <td>82.357143</td>\n      <td>80.551181</td>\n      <td>0.797865</td>\n      <td>0.784930</td>\n      <td>0.030133</td>\n      <td>5.852289</td>\n      <td>5.207305</td>\n      <td>0.011709</td>\n      <td>0.008917</td>\n      <td>0.002738</td>\n      <td>10279936</td>\n      <td>2121785344</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>163</td>\n      <td>163</td>\n      <td>sum</td>\n      <td>None</td>\n      <td>0.0001</td>\n      <td>32</td>\n      <td>RobustPPRGo</td>\n      <td>2</td>\n      <td>64</td>\n      <td>713012254</td>\n      <td>81.000000</td>\n      <td>80.000000</td>\n      <td>0.782417</td>\n      <td>0.774175</td>\n      <td>0.027173</td>\n      <td>5.920595</td>\n      <td>7.054422</td>\n      <td>0.008557</td>\n      <td>0.005861</td>\n      <td>0.002642</td>\n      <td>33509888</td>\n      <td>2360094720</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "# only show columns that don't have the same values in every row\n",
    "best_results.loc[:, (best_results != best_results.iloc[0]).any()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    config.model_class config.aggr  config.topk  result.accuracy_train  \\\n",
       "256              PPRGo         sum           64                  100.0   \n",
       "97               PPRGo        mean           32                  100.0   \n",
       "162        RobustPPRGo         sum           64                  100.0   \n",
       "\n",
       "     result.accuracy_val  result.accuracy_test  result.f1_val  result.f1_val  \\\n",
       "256            84.214286             83.228346       0.824840       0.824840   \n",
       "97             82.357143             80.551181       0.797865       0.797865   \n",
       "162            81.000000             80.000000       0.782417       0.782417   \n",
       "\n",
       "     result.f1_test  \n",
       "256        0.817294  \n",
       "97         0.784930  \n",
       "162        0.774175  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>config.model_class</th>\n      <th>config.aggr</th>\n      <th>config.topk</th>\n      <th>result.accuracy_train</th>\n      <th>result.accuracy_val</th>\n      <th>result.accuracy_test</th>\n      <th>result.f1_val</th>\n      <th>result.f1_val</th>\n      <th>result.f1_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>256</th>\n      <td>PPRGo</td>\n      <td>sum</td>\n      <td>64</td>\n      <td>100.0</td>\n      <td>84.214286</td>\n      <td>83.228346</td>\n      <td>0.824840</td>\n      <td>0.824840</td>\n      <td>0.817294</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>PPRGo</td>\n      <td>mean</td>\n      <td>32</td>\n      <td>100.0</td>\n      <td>82.357143</td>\n      <td>80.551181</td>\n      <td>0.797865</td>\n      <td>0.797865</td>\n      <td>0.784930</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>RobustPPRGo</td>\n      <td>sum</td>\n      <td>64</td>\n      <td>100.0</td>\n      <td>81.000000</td>\n      <td>80.000000</td>\n      <td>0.782417</td>\n      <td>0.782417</td>\n      <td>0.774175</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "config_columns = [\"config.model_class\", \"config.aggr\", \"config.topk\"]\n",
    "perf_res_columns = [ \"result.accuracy_train\", \"result.accuracy_val\", \"result.accuracy_test\", \"result.f1_val\", \"result.f1_val\", \"result.f1_test\"]\n",
    "scal_res_columns = [\"result.time_training\", \"result.time_propagation\",\t\"result.gpu_memory\", \"result.memory\"]\n",
    "\n",
    "best_results[config_columns + perf_res_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    config.model_class config.aggr  config.topk  result.time_training  \\\n",
       "256              PPRGo         sum           64              4.965747   \n",
       "97               PPRGo        mean           32              5.207305   \n",
       "162        RobustPPRGo         sum           64              7.054422   \n",
       "\n",
       "     result.time_propagation  result.gpu_memory  result.memory  \n",
       "256                 0.002694           32934400     2130378752  \n",
       "97                  0.002738           10279936     2121785344  \n",
       "162                 0.002642           33509888     2360094720  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>config.model_class</th>\n      <th>config.aggr</th>\n      <th>config.topk</th>\n      <th>result.time_training</th>\n      <th>result.time_propagation</th>\n      <th>result.gpu_memory</th>\n      <th>result.memory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>256</th>\n      <td>PPRGo</td>\n      <td>sum</td>\n      <td>64</td>\n      <td>4.965747</td>\n      <td>0.002694</td>\n      <td>32934400</td>\n      <td>2130378752</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>PPRGo</td>\n      <td>mean</td>\n      <td>32</td>\n      <td>5.207305</td>\n      <td>0.002738</td>\n      <td>10279936</td>\n      <td>2121785344</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>RobustPPRGo</td>\n      <td>sum</td>\n      <td>64</td>\n      <td>7.054422</td>\n      <td>0.002642</td>\n      <td>33509888</td>\n      <td>2360094720</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "best_results[config_columns + scal_res_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "|     | config.model_class   | config.aggr   |   config.topk |   result.accuracy_train |   result.accuracy_val |   result.accuracy_test |   result.f1_val |   result.f1_val |   result.f1_test |   result.time_training |   result.time_propagation |   result.gpu_memory |   result.memory |\n|----:|:---------------------|:--------------|--------------:|------------------------:|----------------------:|-----------------------:|----------------:|----------------:|-----------------:|-----------------------:|--------------------------:|--------------------:|----------------:|\n| 256 | PPRGo                | sum           |            64 |                     100 |               84.2143 |                83.2283 |        0.82484  |        0.82484  |         0.817294 |                4.96575 |                0.00269389 |            32934400 |      2130378752 |\n|  97 | PPRGo                | mean          |            32 |                     100 |               82.3571 |                80.5512 |        0.797865 |        0.797865 |         0.78493  |                5.2073  |                0.00273752 |            10279936 |      2121785344 |\n| 162 | RobustPPRGo          | sum           |            64 |                     100 |               81      |                80      |        0.782417 |        0.782417 |         0.774175 |                7.05442 |                0.00264239 |            33509888 |      2360094720 |\n"
     ]
    }
   ],
   "source": [
    "print(best_results[config_columns + perf_res_columns+scal_res_columns].to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'config_keys' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-d0917b773a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"config.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseml_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"db_collection\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"seed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config_keys' is not defined"
     ]
    }
   ],
   "source": [
    "_id = 64\n",
    "config = {k.replace(\"config.\", \"\"):v for k, v in seml_results.iloc[24][config_keys].items()}\n",
    "config.pop(\"overwrite\")\n",
    "config.pop(\"db_collection\")\n",
    "config.pop(\"seed\")\n",
    "config[\"batch_size\"] = int(config[\"batch_size\"])\n",
    "config[\"aggr\"] = \"sum\"\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 14:58:25 (INFO): Loading done.\n",
      "2020-12-21 14:58:25 (INFO): Preprocessing done.\n",
      "2020-12-21 14:58:25 (INFO): Epoch 0, step 1: train 0.01390\n",
      "2020-12-21 14:58:25 (INFO): Epoch 1, step 2: train 0.01389\n",
      "2020-12-21 14:58:25 (INFO): Epoch 2, step 3: train 0.01387\n",
      "2020-12-21 14:58:25 (INFO): Epoch 3, step 4: train 0.01384\n",
      "2020-12-21 14:58:25 (INFO): Epoch 4, step 5: train 0.01380\n",
      "2020-12-21 14:58:25 (INFO): Epoch 5, step 6: train 0.01374\n",
      "2020-12-21 14:58:25 (INFO): Epoch 6, step 7: train 0.01367\n",
      "2020-12-21 14:58:25 (INFO): Epoch 7, step 8: train 0.01359\n",
      "2020-12-21 14:58:25 (INFO): Epoch 8, step 9: train 0.01349\n",
      "2020-12-21 14:58:25 (INFO): Epoch 9, step 10: train 0.01337\n",
      "2020-12-21 14:58:25 (INFO): Epoch 10, step 11: train 0.01324\n",
      "2020-12-21 14:58:25 (INFO): Epoch 11, step 12: train 0.01309\n",
      "2020-12-21 14:58:25 (INFO): Epoch 12, step 13: train 0.01293\n",
      "2020-12-21 14:58:25 (INFO): Epoch 13, step 14: train 0.01277\n",
      "2020-12-21 14:58:25 (INFO): Epoch 14, step 15: train 0.01260\n",
      "2020-12-21 14:58:25 (INFO): Epoch 15, step 16: train 0.01243\n",
      "2020-12-21 14:58:25 (INFO): Epoch 16, step 17: train 0.01225\n",
      "2020-12-21 14:58:25 (INFO): Epoch 17, step 18: train 0.01207\n",
      "2020-12-21 14:58:25 (INFO): Epoch 18, step 19: train 0.01189\n",
      "2020-12-21 14:58:25 (INFO): Epoch 19, step 20: train 0.01170\n",
      "2020-12-21 14:58:25 (INFO): Epoch 20, step 21: train 0.01150\n",
      "2020-12-21 14:58:25 (INFO): Epoch 21, step 22: train 0.01131\n",
      "2020-12-21 14:58:25 (INFO): Epoch 22, step 23: train 0.01110\n",
      "2020-12-21 14:58:25 (INFO): Epoch 23, step 24: train 0.01091\n",
      "2020-12-21 14:58:25 (INFO): Epoch 24, step 25: train 0.01071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "<class 'int'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-21 14:58:25 (INFO): Epoch 25, step 26: train 0.01051\n",
      "2020-12-21 14:58:25 (INFO): Epoch 26, step 27: train 0.01030\n",
      "2020-12-21 14:58:25 (INFO): Epoch 27, step 28: train 0.01010\n",
      "2020-12-21 14:58:25 (INFO): Epoch 28, step 29: train 0.00990\n",
      "2020-12-21 14:58:25 (INFO): Epoch 29, step 30: train 0.00970\n",
      "2020-12-21 14:58:25 (INFO): Epoch 30, step 31: train 0.00950\n",
      "2020-12-21 14:58:25 (INFO): Epoch 31, step 32: train 0.00930\n",
      "2020-12-21 14:58:25 (INFO): Epoch 32, step 33: train 0.00910\n",
      "2020-12-21 14:58:25 (INFO): Epoch 33, step 34: train 0.00891\n",
      "2020-12-21 14:58:25 (INFO): Epoch 34, step 35: train 0.00872\n",
      "2020-12-21 14:58:25 (INFO): Epoch 35, step 36: train 0.00853\n",
      "2020-12-21 14:58:25 (INFO): Epoch 36, step 37: train 0.00834\n",
      "2020-12-21 14:58:25 (INFO): Epoch 37, step 38: train 0.00816\n",
      "2020-12-21 14:58:25 (INFO): Epoch 38, step 39: train 0.00798\n",
      "2020-12-21 14:58:25 (INFO): Epoch 39, step 40: train 0.00780\n",
      "2020-12-21 14:58:25 (INFO): Epoch 40, step 41: train 0.00763\n",
      "2020-12-21 14:58:25 (INFO): Epoch 41, step 42: train 0.00746\n",
      "2020-12-21 14:58:25 (INFO): Epoch 42, step 43: train 0.00730\n",
      "2020-12-21 14:58:25 (INFO): Epoch 43, step 44: train 0.00714\n",
      "2020-12-21 14:58:25 (INFO): Epoch 44, step 45: train 0.00699\n",
      "2020-12-21 14:58:25 (INFO): Epoch 45, step 46: train 0.00685\n",
      "2020-12-21 14:58:25 (INFO): Epoch 46, step 47: train 0.00671\n",
      "2020-12-21 14:58:25 (INFO): Epoch 47, step 48: train 0.00657\n",
      "2020-12-21 14:58:25 (INFO): Epoch 48, step 49: train 0.00644\n",
      "2020-12-21 14:58:25 (INFO): Epoch 49, step 50: train 0.00632\n",
      "2020-12-21 14:58:25 (INFO): Epoch 50, step 51: train 0.00620\n",
      "2020-12-21 14:58:25 (INFO): Epoch 51, step 52: train 0.00608\n",
      "2020-12-21 14:58:25 (INFO): Epoch 52, step 53: train 0.00597\n",
      "2020-12-21 14:58:25 (INFO): Epoch 53, step 54: train 0.00586\n",
      "2020-12-21 14:58:25 (INFO): Epoch 54, step 55: train 0.00575\n",
      "2020-12-21 14:58:25 (INFO): Epoch 55, step 56: train 0.00565\n",
      "2020-12-21 14:58:25 (INFO): Epoch 56, step 57: train 0.00555\n",
      "2020-12-21 14:58:25 (INFO): Epoch 57, step 58: train 0.00546\n",
      "2020-12-21 14:58:25 (INFO): Epoch 58, step 59: train 0.00537\n",
      "2020-12-21 14:58:25 (INFO): Epoch 59, step 60: train 0.00528\n",
      "2020-12-21 14:58:25 (INFO): Epoch 60, step 61: train 0.00519\n",
      "2020-12-21 14:58:25 (INFO): Epoch 61, step 62: train 0.00511\n",
      "2020-12-21 14:58:25 (INFO): Epoch 62, step 63: train 0.00503\n",
      "2020-12-21 14:58:25 (INFO): Epoch 63, step 64: train 0.00495\n",
      "2020-12-21 14:58:25 (INFO): Epoch 64, step 65: train 0.00488\n",
      "2020-12-21 14:58:25 (INFO): Epoch 65, step 66: train 0.00480\n",
      "2020-12-21 14:58:25 (INFO): Epoch 66, step 67: train 0.00473\n",
      "2020-12-21 14:58:25 (INFO): Epoch 67, step 68: train 0.00466\n",
      "2020-12-21 14:58:25 (INFO): Epoch 68, step 69: train 0.00460\n",
      "2020-12-21 14:58:25 (INFO): Epoch 69, step 70: train 0.00453\n",
      "2020-12-21 14:58:25 (INFO): Epoch 70, step 71: train 0.00447\n",
      "2020-12-21 14:58:25 (INFO): Epoch 71, step 72: train 0.00441\n",
      "2020-12-21 14:58:25 (INFO): Epoch 72, step 73: train 0.00435\n",
      "2020-12-21 14:58:25 (INFO): Epoch 73, step 74: train 0.00429\n",
      "2020-12-21 14:58:25 (INFO): Epoch 74, step 75: train 0.00423\n",
      "2020-12-21 14:58:25 (INFO): Epoch 75, step 76: train 0.00418\n",
      "2020-12-21 14:58:25 (INFO): Epoch 76, step 77: train 0.00412\n",
      "2020-12-21 14:58:25 (INFO): Epoch 77, step 78: train 0.00407\n",
      "2020-12-21 14:58:25 (INFO): Epoch 78, step 79: train 0.00402\n",
      "2020-12-21 14:58:25 (INFO): Epoch 79, step 80: train 0.00397\n",
      "2020-12-21 14:58:25 (INFO): Epoch 80, step 81: train 0.00392\n",
      "2020-12-21 14:58:25 (INFO): Epoch 81, step 82: train 0.00387\n",
      "2020-12-21 14:58:25 (INFO): Epoch 82, step 83: train 0.00383\n",
      "2020-12-21 14:58:25 (INFO): Epoch 83, step 84: train 0.00378\n",
      "2020-12-21 14:58:25 (INFO): Epoch 84, step 85: train 0.00374\n",
      "2020-12-21 14:58:25 (INFO): Epoch 85, step 86: train 0.00370\n",
      "2020-12-21 14:58:25 (INFO): Epoch 86, step 87: train 0.00365\n",
      "2020-12-21 14:58:25 (INFO): Epoch 87, step 88: train 0.00361\n",
      "2020-12-21 14:58:25 (INFO): Epoch 88, step 89: train 0.00357\n",
      "2020-12-21 14:58:25 (INFO): Epoch 89, step 90: train 0.00353\n",
      "2020-12-21 14:58:25 (INFO): Epoch 90, step 91: train 0.00350\n",
      "2020-12-21 14:58:25 (INFO): Epoch 91, step 92: train 0.00346\n",
      "2020-12-21 14:58:25 (INFO): Epoch 92, step 93: train 0.00342\n",
      "2020-12-21 14:58:25 (INFO): Epoch 93, step 94: train 0.00339\n",
      "2020-12-21 14:58:25 (INFO): Epoch 94, step 95: train 0.00335\n",
      "2020-12-21 14:58:25 (INFO): Epoch 95, step 96: train 0.00332\n",
      "2020-12-21 14:58:25 (INFO): Epoch 96, step 97: train 0.00328\n",
      "2020-12-21 14:58:25 (INFO): Epoch 97, step 98: train 0.00325\n",
      "2020-12-21 14:58:25 (INFO): Epoch 98, step 99: train 0.00322\n",
      "2020-12-21 14:58:25 (INFO): Epoch 99, step 100: train 0.00319\n",
      "2020-12-21 14:58:25 (INFO): Epoch 100, step 101: train 0.00315\n",
      "2020-12-21 14:58:25 (INFO): Epoch 101, step 102: train 0.00312\n",
      "2020-12-21 14:58:25 (INFO): Epoch 102, step 103: train 0.00309\n",
      "2020-12-21 14:58:25 (INFO): Epoch 103, step 104: train 0.00307\n",
      "2020-12-21 14:58:25 (INFO): Epoch 104, step 105: train 0.00304\n",
      "2020-12-21 14:58:25 (INFO): Epoch 105, step 106: train 0.00301\n",
      "2020-12-21 14:58:25 (INFO): Epoch 106, step 107: train 0.00298\n",
      "2020-12-21 14:58:25 (INFO): Epoch 107, step 108: train 0.00295\n",
      "2020-12-21 14:58:25 (INFO): Epoch 108, step 109: train 0.00293\n",
      "2020-12-21 14:58:25 (INFO): Epoch 109, step 110: train 0.00290\n",
      "2020-12-21 14:58:25 (INFO): Epoch 110, step 111: train 0.00288\n",
      "2020-12-21 14:58:25 (INFO): Epoch 111, step 112: train 0.00285\n",
      "2020-12-21 14:58:25 (INFO): Epoch 112, step 113: train 0.00283\n",
      "2020-12-21 14:58:25 (INFO): Epoch 113, step 114: train 0.00280\n",
      "2020-12-21 14:58:25 (INFO): Epoch 114, step 115: train 0.00278\n",
      "2020-12-21 14:58:25 (INFO): Epoch 115, step 116: train 0.00275\n",
      "2020-12-21 14:58:25 (INFO): Epoch 116, step 117: train 0.00273\n",
      "2020-12-21 14:58:25 (INFO): Epoch 117, step 118: train 0.00271\n",
      "2020-12-21 14:58:25 (INFO): Epoch 118, step 119: train 0.00269\n",
      "2020-12-21 14:58:25 (INFO): Epoch 119, step 120: train 0.00266\n",
      "2020-12-21 14:58:25 (INFO): Epoch 120, step 121: train 0.00264\n",
      "2020-12-21 14:58:25 (INFO): Epoch 121, step 122: train 0.00262\n",
      "2020-12-21 14:58:25 (INFO): Epoch 122, step 123: train 0.00260\n",
      "2020-12-21 14:58:25 (INFO): Epoch 123, step 124: train 0.00258\n",
      "2020-12-21 14:58:25 (INFO): Epoch 124, step 125: train 0.00256\n",
      "2020-12-21 14:58:25 (INFO): Epoch 125, step 126: train 0.00254\n",
      "2020-12-21 14:58:25 (INFO): Epoch 126, step 127: train 0.00252\n",
      "2020-12-21 14:58:25 (INFO): Epoch 127, step 128: train 0.00250\n",
      "2020-12-21 14:58:25 (INFO): Epoch 128, step 129: train 0.00248\n",
      "2020-12-21 14:58:25 (INFO): Epoch 129, step 130: train 0.00246\n",
      "2020-12-21 14:58:25 (INFO): Epoch 130, step 131: train 0.00245\n",
      "2020-12-21 14:58:25 (INFO): Epoch 131, step 132: train 0.00243\n",
      "2020-12-21 14:58:25 (INFO): Epoch 132, step 133: train 0.00241\n",
      "2020-12-21 14:58:25 (INFO): Epoch 133, step 134: train 0.00239\n",
      "2020-12-21 14:58:25 (INFO): Epoch 134, step 135: train 0.00237\n",
      "2020-12-21 14:58:25 (INFO): Epoch 135, step 136: train 0.00236\n",
      "2020-12-21 14:58:25 (INFO): Epoch 136, step 137: train 0.00234\n",
      "2020-12-21 14:58:25 (INFO): Epoch 137, step 138: train 0.00232\n",
      "2020-12-21 14:58:25 (INFO): Epoch 138, step 139: train 0.00231\n",
      "2020-12-21 14:58:25 (INFO): Epoch 139, step 140: train 0.00229\n",
      "2020-12-21 14:58:25 (INFO): Epoch 140, step 141: train 0.00228\n",
      "2020-12-21 14:58:25 (INFO): Epoch 141, step 142: train 0.00226\n",
      "2020-12-21 14:58:25 (INFO): Epoch 142, step 143: train 0.00224\n",
      "2020-12-21 14:58:25 (INFO): Epoch 143, step 144: train 0.00223\n",
      "2020-12-21 14:58:25 (INFO): Epoch 144, step 145: train 0.00221\n",
      "2020-12-21 14:58:25 (INFO): Epoch 145, step 146: train 0.00220\n",
      "2020-12-21 14:58:25 (INFO): Epoch 146, step 147: train 0.00218\n",
      "2020-12-21 14:58:25 (INFO): Epoch 147, step 148: train 0.00217\n",
      "2020-12-21 14:58:25 (INFO): Epoch 148, step 149: train 0.00216\n",
      "2020-12-21 14:58:25 (INFO): Epoch 149, step 150: train 0.00214\n",
      "2020-12-21 14:58:25 (INFO): Epoch 150, step 151: train 0.00213\n",
      "2020-12-21 14:58:25 (INFO): Epoch 151, step 152: train 0.00211\n",
      "2020-12-21 14:58:25 (INFO): Epoch 152, step 153: train 0.00210\n",
      "2020-12-21 14:58:25 (INFO): Epoch 153, step 154: train 0.00209\n",
      "2020-12-21 14:58:25 (INFO): Epoch 154, step 155: train 0.00207\n",
      "2020-12-21 14:58:25 (INFO): Epoch 155, step 156: train 0.00206\n",
      "2020-12-21 14:58:25 (INFO): Epoch 156, step 157: train 0.00205\n",
      "2020-12-21 14:58:25 (INFO): Epoch 157, step 158: train 0.00204\n",
      "2020-12-21 14:58:25 (INFO): Epoch 158, step 159: train 0.00202\n",
      "2020-12-21 14:58:25 (INFO): Epoch 159, step 160: train 0.00201\n",
      "2020-12-21 14:58:25 (INFO): Epoch 160, step 161: train 0.00200\n",
      "2020-12-21 14:58:25 (INFO): Epoch 161, step 162: train 0.00199\n",
      "2020-12-21 14:58:25 (INFO): Epoch 162, step 163: train 0.00198\n",
      "2020-12-21 14:58:25 (INFO): Epoch 163, step 164: train 0.00196\n",
      "2020-12-21 14:58:25 (INFO): Epoch 164, step 165: train 0.00195\n",
      "2020-12-21 14:58:25 (INFO): Epoch 165, step 166: train 0.00194\n",
      "2020-12-21 14:58:25 (INFO): Epoch 166, step 167: train 0.00193\n",
      "2020-12-21 14:58:25 (INFO): Epoch 167, step 168: train 0.00192\n",
      "2020-12-21 14:58:25 (INFO): Epoch 168, step 169: train 0.00191\n",
      "2020-12-21 14:58:25 (INFO): Epoch 169, step 170: train 0.00190\n",
      "2020-12-21 14:58:25 (INFO): Epoch 170, step 171: train 0.00188\n",
      "2020-12-21 14:58:25 (INFO): Epoch 171, step 172: train 0.00187\n",
      "2020-12-21 14:58:26 (INFO): Epoch 172, step 173: train 0.00186\n",
      "2020-12-21 14:58:26 (INFO): Epoch 173, step 174: train 0.00185\n",
      "2020-12-21 14:58:26 (INFO): Epoch 174, step 175: train 0.00184\n",
      "2020-12-21 14:58:26 (INFO): Epoch 175, step 176: train 0.00183\n",
      "2020-12-21 14:58:26 (INFO): Epoch 176, step 177: train 0.00182\n",
      "2020-12-21 14:58:26 (INFO): Epoch 177, step 178: train 0.00181\n",
      "2020-12-21 14:58:26 (INFO): Epoch 178, step 179: train 0.00180\n",
      "2020-12-21 14:58:26 (INFO): Epoch 179, step 180: train 0.00179\n",
      "2020-12-21 14:58:26 (INFO): Epoch 180, step 181: train 0.00178\n",
      "2020-12-21 14:58:26 (INFO): Epoch 181, step 182: train 0.00177\n",
      "2020-12-21 14:58:26 (INFO): Epoch 182, step 183: train 0.00176\n",
      "2020-12-21 14:58:26 (INFO): Epoch 183, step 184: train 0.00175\n",
      "2020-12-21 14:58:26 (INFO): Epoch 184, step 185: train 0.00175\n",
      "2020-12-21 14:58:26 (INFO): Epoch 185, step 186: train 0.00174\n",
      "2020-12-21 14:58:26 (INFO): Epoch 186, step 187: train 0.00173\n",
      "2020-12-21 14:58:26 (INFO): Epoch 187, step 188: train 0.00172\n",
      "2020-12-21 14:58:26 (INFO): Epoch 188, step 189: train 0.00171\n",
      "2020-12-21 14:58:26 (INFO): Epoch 189, step 190: train 0.00170\n",
      "2020-12-21 14:58:26 (INFO): Epoch 190, step 191: train 0.00169\n",
      "2020-12-21 14:58:26 (INFO): Epoch 191, step 192: train 0.00168\n",
      "2020-12-21 14:58:26 (INFO): Epoch 192, step 193: train 0.00167\n",
      "2020-12-21 14:58:26 (INFO): Epoch 193, step 194: train 0.00167\n",
      "2020-12-21 14:58:26 (INFO): Epoch 194, step 195: train 0.00166\n",
      "2020-12-21 14:58:26 (INFO): Epoch 195, step 196: train 0.00165\n",
      "2020-12-21 14:58:26 (INFO): Epoch 196, step 197: train 0.00164\n",
      "2020-12-21 14:58:26 (INFO): Epoch 197, step 198: train 0.00163\n",
      "2020-12-21 14:58:26 (INFO): Epoch 198, step 199: train 0.00163\n",
      "2020-12-21 14:58:26 (INFO): Epoch 199, step 200: train 0.00162\n",
      "2020-12-21 14:58:26 (INFO): Training done.\n",
      "2020-12-21 14:58:26 (INFO): Inference done.\n"
     ]
    }
   ],
   "source": [
    "results = run(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 100.0,\n",
       " 'accuracy_val': 82.71428571428572,\n",
       " 'accuracy_test': 81.65354330708662,\n",
       " 'f1_train': 1.0,\n",
       " 'f1_val': 0.808732503433484,\n",
       " 'f1_test': 0.8039586412758616,\n",
       " 'time_loading': 0.021263599395751953,\n",
       " 'time_preprocessing': 0.0038497447967529297,\n",
       " 'time_training': 1.0438570976257324,\n",
       " 'time_inference': 0.006062984466552734,\n",
       " 'time_logits': 0.004880666732788086,\n",
       " 'time_propagation': 0.0011315345764160156,\n",
       " 'gpu_memory': 15502336,\n",
       " 'memory': 2118467584,\n",
       " 'nepochs': 200}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}